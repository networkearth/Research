{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ceb9a46d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "\n",
    "os.environ['AWS_PROFILE'] = 'admin'\n",
    "os.environ['HAVEN_DATABASE'] = 'haven'\n",
    "\n",
    "import plotly.express as px\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import h3\n",
    "\n",
    "from mirrorverse.utils import read_data_w_cache"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c333a26",
   "metadata": {},
   "source": [
    "# Model Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2972638",
   "metadata": {},
   "source": [
    "## Helpful Stuff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8719bda9",
   "metadata": {},
   "outputs": [],
   "source": [
    "MODELS = {\n",
    "    'A': ('3_1_1', 'ab17d4ce30981b9d7630da4d7adbf7fd7cb88a9bfee2b37ed60254e097e8ffdc'),\n",
    "    'B': ('3_1_3', 'e875c3a83c56925e0537b30c6f64d3219ffcd41c2298490d69eec4c25899119c'),\n",
    "    'C': ('3_1_4', '00cf23b296999368ea18b82e33b8687c51e8c35e876afd325e26317cb69ea45b'),\n",
    "    'D': ('3_7_2', 'fb3f06dc5fd0971a4e7cfdd2e5da5cca391a633f92528e79aa526df347ca0920'),\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b41046a",
   "metadata": {},
   "source": [
    "## Overall Model Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5578192",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs = []\n",
    "for model_name, (model_id, run_id) in MODELS.items():\n",
    "    sql = f'''\n",
    "    with likelihoods as (\n",
    "        select\n",
    "            _individual,\n",
    "            '{model_name}' as model,\n",
    "            _train, \n",
    "            avg(ln(probability)) as nll\n",
    "        from \n",
    "            chinook_depth_inference_{model_id}\n",
    "        where \n",
    "            run_id = '{run_id}'\n",
    "            and _selected\n",
    "        group by \n",
    "            1, 2, 3\n",
    "    )\n",
    "    select\n",
    "        model,\n",
    "        _train,\n",
    "        avg(nll) as nll\n",
    "    from \n",
    "        likelihoods\n",
    "    group by \n",
    "        1, 2\n",
    "    '''\n",
    "    dfs.append(read_data_w_cache(sql))\n",
    "\n",
    "\n",
    "sql = f'''\n",
    "with probabilities as (\n",
    "    select\n",
    "        _individual,\n",
    "        _decision,\n",
    "        _train, \n",
    "        1.0 / cast(count(*) as double) as probability\n",
    "    from \n",
    "        chinook_depth_inference_{model_id}\n",
    "    where \n",
    "        run_id = '{run_id}'\n",
    "    group by \n",
    "        1, 2, 3\n",
    "), likelihoods as (\n",
    "    select\n",
    "        _individual,\n",
    "        'Null' as model,\n",
    "        _train, \n",
    "        avg(ln(probability)) as nll\n",
    "    from \n",
    "        probabilities\n",
    "    group by \n",
    "        1, 2, 3\n",
    ")\n",
    "select\n",
    "    model,\n",
    "    _train,\n",
    "    avg(nll) as nll\n",
    "from \n",
    "    likelihoods\n",
    "group by \n",
    "    1, 2\n",
    "'''\n",
    "dfs.append(read_data_w_cache(sql))\n",
    "\n",
    "data = pd.concat(dfs).sort_values(['_train', 'model']).reset_index(drop=True)\n",
    "print(data.shape)\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d84fcc59",
   "metadata": {},
   "source": [
    "## Depth Skew"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "898d5e8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name, (model_id, run_id) = next(iter(MODELS.items()))\n",
    "\n",
    "sql = f'''\n",
    "select\n",
    "    depth_bin,\n",
    "    count(*) as count\n",
    "from \n",
    "    chinook_depth_inference_{model_id}\n",
    "where\n",
    "    run_id = '{run_id}'\n",
    "    and _selected\n",
    "group by \n",
    "    1\n",
    "'''\n",
    "data = read_data_w_cache(sql)\n",
    "data['proportion'] = data['count'] / data['count'].sum()\n",
    "data.sort_values('depth_bin', ascending=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99855b34",
   "metadata": {},
   "outputs": [],
   "source": [
    "sql = f'''\n",
    "select\n",
    "    depth_bin,\n",
    "    sum(probability) as count\n",
    "from \n",
    "    chinook_depth_inference_3_7_2\n",
    "where\n",
    "    run_id = 'fb3f06dc5fd0971a4e7cfdd2e5da5cca391a633f92528e79aa526df347ca0920'\n",
    "group by \n",
    "    1\n",
    "'''\n",
    "data = read_data_w_cache(sql)\n",
    "data['proportion'] = data['count'] / data['count'].sum()\n",
    "data.sort_values('depth_bin', ascending=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bf8087b",
   "metadata": {},
   "outputs": [],
   "source": [
    "data[data['depth_bin'] <= 100].sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "651d53a1",
   "metadata": {},
   "source": [
    "## Seasonality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96b42f7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "color_discrete_map = {\n",
    "    \"25.0\": \"#1b9e77\",  # Green\n",
    "    \"50.0\": \"#d95f02\",  # Orange\n",
    "    \"75.0\": \"#7570b3\",  # Purple\n",
    "    \"100.0\": \"#e7298a\",  # Pink\n",
    "    \"150.0\": \"#66a61e\",  # Olive Green\n",
    "    \"200.0\": \"#e6ab02\",  # Yellow-Orange\n",
    "    \"250.0\": \"#a6761d\",  # Brown\n",
    "    \"300.0\": \"#666666\",  # Gray\n",
    "    \"400.0\": \"#1f78b4\",  # Blue\n",
    "    \"500.0\": \"#a6cee3\",  # Light Blue\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd4cd4e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_id = '3_7_2'\n",
    "run_id = 'fb3f06dc5fd0971a4e7cfdd2e5da5cca391a633f92528e79aa526df347ca0920'\n",
    "sql = f'''\n",
    "select\n",
    "    extract(month from time) as month,\n",
    "    depth_bin,\n",
    "    count(*) as count\n",
    "from \n",
    "    chinook_depth_inference_{model_id}\n",
    "where\n",
    "    run_id = '{run_id}'\n",
    "    and _selected\n",
    "group by \n",
    "    1, 2\n",
    "'''\n",
    "actuals = read_data_w_cache(sql)\n",
    "actuals['monthly_count'] = actuals.groupby('month')['count'].transform('sum')\n",
    "actuals['proportion'] = actuals['count'] / actuals['monthly_count']\n",
    "actuals['depth_bin'] = actuals['depth_bin'].astype(str)\n",
    "actuals['case'] = 'actual'\n",
    "px.bar(\n",
    "    actuals, x='month', y='proportion', color='depth_bin', \n",
    "    color_discrete_map=color_discrete_map,\n",
    "    category_orders={'depth_bin': color_discrete_map.keys()},\n",
    "    title=\"Actual Proportion per Depth Bin by Month (Val)\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ce2221a",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_id = '3_7_2'\n",
    "run_id = 'fb3f06dc5fd0971a4e7cfdd2e5da5cca391a633f92528e79aa526df347ca0920'\n",
    "sql = f'''\n",
    "select\n",
    "    extract(month from time) as month,\n",
    "    depth_bin,\n",
    "    sum(probability) as count\n",
    "from \n",
    "    chinook_depth_inference_{model_id}\n",
    "where\n",
    "    run_id = '{run_id}'\n",
    "group by \n",
    "    1, 2\n",
    "'''\n",
    "val = read_data_w_cache(sql)\n",
    "val['monthly_count'] = val.groupby('month')['count'].transform('sum')\n",
    "val['proportion'] = val['count'] / val['monthly_count']\n",
    "val['depth_bin'] = val['depth_bin'].astype(str)\n",
    "val['case'] = 'predicted'\n",
    "px.bar(\n",
    "    val, x='month', y='proportion', color='depth_bin', \n",
    "    color_discrete_map=color_discrete_map,\n",
    "    category_orders={'depth_bin': color_discrete_map.keys()},\n",
    "    title=\"Predicted Proportion per Depth Bin by Month (Val)\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26df9a64",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.concat([val, actuals])\n",
    "MONTHS = {\n",
    "    1: 'Jan',\n",
    "    2: 'Feb',\n",
    "    3: 'Mar',\n",
    "    4: 'Apr',\n",
    "    5: 'May',\n",
    "    6: 'Jun',\n",
    "    7: 'Jul',\n",
    "    8: 'Aug',\n",
    "    9: 'Sep',\n",
    "    10: 'Oct',\n",
    "    11: 'Nov',\n",
    "    12: 'Dec'\n",
    "}\n",
    "df[\"month\"] = df[\"month\"].apply(lambda m: MONTHS[m])\n",
    "fig = px.bar(\n",
    "    df, x='month', y='proportion', color='depth_bin', \n",
    "    color_discrete_map=color_discrete_map,\n",
    "    category_orders={'depth_bin': color_discrete_map.keys(), \"case\": [\"actual\", \"predicted\"], \"month\": list(MONTHS.values())},\n",
    "    title=\"Proportion per Depth Bin by Month\",\n",
    "    facet_row=\"case\", height=500, width=800\n",
    ")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "808e8faf",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig.write_image(\"fig2_seasonality.png\", format=\"png\", scale=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05ee7af4",
   "metadata": {},
   "source": [
    "## Diel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d5f54f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_id = '3_7_2'\n",
    "run_id = 'fb3f06dc5fd0971a4e7cfdd2e5da5cca391a633f92528e79aa526df347ca0920'\n",
    "\n",
    "sql = f'''\n",
    "select\n",
    "    extract(month from time) as month,\n",
    "    cos_sun,\n",
    "    sin_sun,\n",
    "    _train,\n",
    "    case \n",
    "        when depth_bin = 25 then 'shallow'\n",
    "        else 'deep' \n",
    "    end as _case,\n",
    "    sum(case when _selected then 1.0 else 0.0 end) as num_selected,\n",
    "    sum(probability) as expected_num_selected\n",
    "from \n",
    "    chinook_depth_inference_{model_id}\n",
    "where\n",
    "    run_id = '{run_id}'\n",
    "group by \n",
    "    1, 2, 3, 4, 5\n",
    "'''\n",
    "data = read_data_w_cache(sql)\n",
    "data['radians'] = np.arctan2(data['sin_sun'], data['cos_sun'])\n",
    "data['radians'] = round(data['radians'] * 5) / 5\n",
    "data = data.groupby(['month', '_train', 'radians', '_case'])[['num_selected', 'expected_num_selected']].sum().reset_index()\n",
    "data['total_num_selected'] = data.groupby(['month', '_train', 'radians'])['num_selected'].transform('sum')\n",
    "data['proportion'] = data['num_selected'] / data['total_num_selected']\n",
    "data['predicted_proportion'] = data['expected_num_selected'] / data['total_num_selected']\n",
    "\n",
    "data = pd.concat([\n",
    "    data[data['_train']].assign(case='train').drop(columns=['predicted_proportion']),\n",
    "    data[~data['_train']].assign(case='validation').drop(columns=['predicted_proportion']),\n",
    "    data[~data['_train']].assign(case='predicted').drop(columns=['proportion']).rename(columns={'predicted_proportion': 'proportion'})\n",
    "])\n",
    "\n",
    "data[\"month\"] = data[\"month\"].apply(lambda m: MONTHS[m])\n",
    "\n",
    "fig = px.scatter(\n",
    "    data[data['_case'] == 'deep'], x='radians', y='proportion', color='case',\n",
    "    facet_col='month', facet_col_wrap=4,\n",
    "    title=\"Proportion Deeper than 25m by Time of Day\", category_orders={'month': list(MONTHS.values())},\n",
    "    height=900, width=1000, color_discrete_map={\n",
    "        'train': 'blue', 'validation': 'orange', 'predicted': 'purple'\n",
    "    }\n",
    ")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e84f6893",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig.write_image(\"fig3_diel.png\", format=\"png\", scale=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3af35f78",
   "metadata": {},
   "outputs": [],
   "source": [
    "sql = f'''\n",
    "select\n",
    "    cos_sun,\n",
    "    sin_sun,\n",
    "    tag_key,\n",
    "    case \n",
    "        when depth_bin = 25 then 'shallow'\n",
    "        else 'deep' \n",
    "    end as _case,\n",
    "    sum(case when _selected then 1.0 else 0.0 end) as num_selected\n",
    "from \n",
    "    chinook_depth_inference_{model_id}\n",
    "where\n",
    "    run_id = '{run_id}'\n",
    "    and extract(month from time) = 8\n",
    "group by \n",
    "    1, 2, 3, 4\n",
    "'''\n",
    "data = read_data_w_cache(sql)\n",
    "data['radians'] = np.arctan2(data['sin_sun'], data['cos_sun'])\n",
    "data['day'] = data['radians'] > 0\n",
    "data = data.groupby(['tag_key', 'day', '_case'])[['num_selected']].sum().reset_index()\n",
    "data['total_selected'] = data.groupby(['tag_key', 'day'])['num_selected'].transform('sum')\n",
    "data['proportion'] = data['num_selected'] / data['total_selected']\n",
    "print(data.shape)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a303fc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "px.histogram(data[data['_case'] == 'shallow'], x='proportion', color='day', barmode='group')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5e4392d",
   "metadata": {},
   "outputs": [],
   "source": [
    "data['tag_key'].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "241b1121",
   "metadata": {},
   "outputs": [],
   "source": [
    "data[data['day'] & (data['proportion'] > .70) & (data['_case'] == 'shallow')].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76976057",
   "metadata": {},
   "outputs": [],
   "source": [
    "data[data['day'] & (data['proportion'] < .15) & (data['_case'] == 'shallow')].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e98d901f",
   "metadata": {},
   "outputs": [],
   "source": [
    "data[data['day'] & (data['proportion'] < .3) & (data['_case'] == 'shallow')].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2ba4f9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "data[~data['day'] & (data['proportion'] < .50) & (data['_case'] == 'shallow')].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "504cafa9",
   "metadata": {},
   "outputs": [],
   "source": [
    "data[~data['day'] & (data['proportion'] > .85) & (data['_case'] == 'shallow')].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c65b74b8",
   "metadata": {},
   "source": [
    "## Salinity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9e56a17",
   "metadata": {},
   "outputs": [],
   "source": [
    "sql = '''\n",
    "select\n",
    "    salinity\n",
    "from \n",
    "    chinook_depth_inference_3_7_2\n",
    "where \n",
    "    run_id = 'fb3f06dc5fd0971a4e7cfdd2e5da5cca391a633f92528e79aa526df347ca0920'\n",
    "    and depth_bin = 25\n",
    "'''\n",
    "boundary = read_data_w_cache(sql)['salinity'].quantile(0.25)\n",
    "print(boundary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7607f77",
   "metadata": {},
   "outputs": [],
   "source": [
    "sql = f'''\n",
    "with surface_salinity as (\n",
    "    select\n",
    "        _individual,\n",
    "        _decision,\n",
    "        _train,\n",
    "        salinity as surface_salinity\n",
    "    from \n",
    "        chinook_depth_inference_3_7_2\n",
    "    where \n",
    "        run_id = 'fb3f06dc5fd0971a4e7cfdd2e5da5cca391a633f92528e79aa526df347ca0920'\n",
    "        and depth_bin = 25\n",
    "), max_depth_bins as (\n",
    "    select\n",
    "        _individual,\n",
    "        _decision,\n",
    "        _train,\n",
    "        max(depth_bin) as max_depth_bin\n",
    "    from \n",
    "        chinook_depth_inference_3_7_2\n",
    "    where \n",
    "        run_id = 'fb3f06dc5fd0971a4e7cfdd2e5da5cca391a633f92528e79aa526df347ca0920'\n",
    "    group by \n",
    "        1, 2, 3\n",
    ")\n",
    "select\n",
    "    extract(month from time) as month,\n",
    "    max_depth_bin,\n",
    "    case \n",
    "        when surface_salinity < {boundary} then 'low'\n",
    "        else 'high'\n",
    "    end as surface_salinity,\n",
    "    sum(case when _selected then 1.0 else 0.0 end) as num_selected,\n",
    "    sum(probability) as expected_num_selected,\n",
    "    count(*) as samples\n",
    "from \n",
    "    chinook_depth_inference_3_7_2\n",
    "    inner join surface_salinity\n",
    "        using (_individual, _decision, _train)\n",
    "    inner join max_depth_bins\n",
    "        using (_individual, _decision, _train)\n",
    "where \n",
    "    run_id = 'fb3f06dc5fd0971a4e7cfdd2e5da5cca391a633f92528e79aa526df347ca0920'\n",
    "    and depth_bin = 25\n",
    "group by \n",
    "    1, 2, 3      \n",
    "\n",
    "'''\n",
    "data = read_data_w_cache(sql)\n",
    "data['proportion'] = data['num_selected'] / data['samples']\n",
    "data['predicted_proportion'] = data['expected_num_selected'] / data['samples']\n",
    "data = data.groupby(['month', 'surface_salinity'])['predicted_proportion'].mean().reset_index()\n",
    "print(data.shape)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "646849f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "data[\"month\"] = data[\"month\"].apply(lambda m: MONTHS[m])\n",
    "fig = px.bar(\n",
    "    data, x='month', y='predicted_proportion', barmode='group', \n",
    "    color='surface_salinity', category_orders={\"month\": list(MONTHS.values())},\n",
    "    title=\"Predicted Proportion Near Surface by Surface Salinity\",\n",
    "    height=400, width=800\n",
    ")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f09b3d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig.write_image(\"fig4_salinity1.png\", format=\"png\", scale=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd522e7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "sql = '''\n",
    "select \n",
    "    _train,\n",
    "    extract(month from time) as month,\n",
    "    avg(ln(probability)) as loss\n",
    "from\n",
    "    chinook_depth_inference_3_7_2\n",
    "where \n",
    "    run_id = 'fb3f06dc5fd0971a4e7cfdd2e5da5cca391a633f92528e79aa526df347ca0920'\n",
    "    and _selected\n",
    "group by 1, 2\n",
    "order by 1\n",
    "'''\n",
    "salinity = read_data_w_cache(sql)\n",
    "print(salinity.shape)\n",
    "salinity.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "721b6086",
   "metadata": {},
   "outputs": [],
   "source": [
    "sql = '''\n",
    "select \n",
    "    _train,\n",
    "    extract(month from time) as month,\n",
    "    avg(ln(probability)) as loss\n",
    "from\n",
    "    chinook_depth_inference_3_1_4\n",
    "where \n",
    "    run_id = '00cf23b296999368ea18b82e33b8687c51e8c35e876afd325e26317cb69ea45b'\n",
    "    and _selected\n",
    "group by 1, 2\n",
    "order by 1\n",
    "'''\n",
    "base = read_data_w_cache(sql)\n",
    "base.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7391fb8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = base.merge(salinity, on=['month', '_train'], suffixes=('', '_w_salinity'))\n",
    "df['difference'] = -(df['loss_w_salinity'] - df['loss'])\n",
    "df.sort_values(['month', '_train']).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2c33770",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['month'] = df['month'].apply(lambda m: MONTHS[m])\n",
    "fig = px.bar(\n",
    "    df, x='month', y='difference', color='_train', barmode='group',\n",
    "    category_orders={'month': list(MONTHS.values())},\n",
    "    title='Variation in Change in Loss with Salinity as a Feature',\n",
    "    height=400, width=800\n",
    ")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db8b2953",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig.write_image(\"fig5_salinity2.png\", format=\"png\", scale=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dafefe83",
   "metadata": {},
   "source": [
    "# Assessing Likelihood of Occupancy Near the Seafloor"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b342014a",
   "metadata": {},
   "source": [
    "## Spatial Distribution of Minimum Likelihood"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f4213d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "sql = '''\n",
    "with risk as (\n",
    "    select \n",
    "        time, \n",
    "        epoch,\n",
    "        h3_index,\n",
    "        depth_bin,\n",
    "        max(elevation) as elevation,\n",
    "        sum(probability) as risk\n",
    "    from \n",
    "        chinook_depth_full_inference_3_7_2\n",
    "    where \n",
    "        run_id = 'fb3f06dc5fd0971a4e7cfdd2e5da5cca391a633f92528e79aa526df347ca0920'\n",
    "    group by \n",
    "        1, 2, 3, 4\n",
    "), max_depth_bin as (\n",
    "    select \n",
    "        time, \n",
    "        epoch,\n",
    "        h3_index,\n",
    "        max(depth_bin) as depth_bin\n",
    "    from \n",
    "        chinook_depth_full_inference_3_7_2\n",
    "    where \n",
    "        run_id = 'fb3f06dc5fd0971a4e7cfdd2e5da5cca391a633f92528e79aa526df347ca0920'\n",
    "    group by \n",
    "        1, 2, 3\n",
    ")\n",
    "select \n",
    "    month(time) as month,\n",
    "    h3_index,\n",
    "    depth_bin,\n",
    "    elevation,\n",
    "    approx_percentile(risk, 0.05) as min_risk_month,\n",
    "    approx_percentile(risk, 0.95) as max_risk_month\n",
    "from \n",
    "    risk inner join max_depth_bin using (time, epoch, h3_index, depth_bin)\n",
    "group by \n",
    "    1, 2, 3, 4\n",
    "'''\n",
    "data = read_data_w_cache(sql)\n",
    "data['lat'] = data['h3_index'].apply(lambda x: h3.h3_to_geo(x)[0])\n",
    "data['lon'] = data['h3_index'].apply(lambda x: h3.h3_to_geo(x)[1])\n",
    "print(data.shape)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f565b2c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data[data['depth_bin'] + 100 > -data['elevation']]\n",
    "print(data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3790e49f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from shapely.geometry import Polygon, Point\n",
    "\n",
    "poly = Polygon(\n",
    "    [\n",
    "        (-166, 54.4),\n",
    "        (-160, 56),\n",
    "        (-158, 57.2),\n",
    "        (-153, 62),\n",
    "        (-149, 62),\n",
    "        (-146, 62),\n",
    "        (-140, 60),\n",
    "        (-136, 58.4),\n",
    "        (-133, 57.5),\n",
    "        (-132, 56.0),\n",
    "        (-131, 55),\n",
    "        (-125, 50.3),\n",
    "        (-170, 52.5),\n",
    "        (-166, 54.4),\n",
    "    ]\n",
    ")\n",
    "data['inside_polygon'] = data.apply(lambda row: poly.contains(Point(row['lon'], row['lat'])), axis=1)\n",
    "fig = px.scatter_mapbox(\n",
    "    data[(data['month'] == 2)  & (data['depth_bin'] != 25.0)],\n",
    "    lat='lat',\n",
    "    lon='lon',\n",
    "    color='inside_polygon',  # Color points by probability\n",
    "    size_max=10,  # Adjust as needed\n",
    "    zoom=3,  # Adjust zoom level\n",
    "    mapbox_style=\"carto-positron\",  # Choose a map style,\n",
    "    range_color=[0.0, 0.3]\n",
    ")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3114f1ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data[data['inside_polygon']]\n",
    "data = data[data['lon'] < -145]\n",
    "data['size'] = 0.01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d86c682",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = px.scatter_mapbox(\n",
    "    data[(data['month'] == 2)  & (data['depth_bin'] != 25.0)],\n",
    "    lat='lat',\n",
    "    lon='lon',\n",
    "    color='min_risk_month',  # Color points by probability\n",
    "    size='size',  # Adjust as needed\n",
    "    size_max=11,  # Adjust as needed\n",
    "    zoom=4,  # Adjust zoom level\n",
    "    mapbox_style=\"carto-positron\",  # Choose a map style,\n",
    "    title='Spatial Pattern of Minimal Probability in Bottom Depth Bin in February',\n",
    "    #range_color=[0.0, 0.3],\n",
    "    height=600,\n",
    "    width=1000\n",
    ")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71480a22",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = px.scatter_mapbox(\n",
    "    data[(data['month'] == 8) & (data['depth_bin'] != 25.0)],\n",
    "    lat='lat',\n",
    "    lon='lon',\n",
    "    color='min_risk_month',  # Color points by probability\n",
    "    size='size',  # Adjust as needed\n",
    "    size_max=11,  # Adjust as needed\n",
    "    zoom=4,  # Adjust zoom level\n",
    "    mapbox_style=\"carto-positron\",  # Choose a map style,\n",
    "    title='Spatial Pattern of Minimal Probability in Bottom Depth Bin in August',\n",
    "    #range_color=[0.0, 0.3],\n",
    "    height=600,\n",
    "    width=1000\n",
    ")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f941345",
   "metadata": {},
   "outputs": [],
   "source": [
    "from plotly.subplots import make_subplots\n",
    "import plotly.graph_objects as go\n",
    "\n",
    "# Create subplot figure with 1 row and 2 columns\n",
    "fig = make_subplots(\n",
    "    rows=1, cols=2,\n",
    "    subplot_titles=('February', 'August'),\n",
    "    specs=[[{'type': 'mapbox'}, {'type': 'mapbox'}]],\n",
    "    horizontal_spacing=0.01\n",
    ")\n",
    "\n",
    "# Prepare February data\n",
    "feb_data = data[(data['month'] == 2) & (data['depth_bin'] != 25.0)]\n",
    "\n",
    "# Prepare August data\n",
    "aug_data = data[(data['month'] == 8) & (data['depth_bin'] != 25.0)]\n",
    "\n",
    "color_min = min(feb_data['min_risk_month'].min(), aug_data['min_risk_month'].min())\n",
    "color_max = max(feb_data['min_risk_month'].max(), aug_data['min_risk_month'].max())\n",
    "\n",
    "\n",
    "# Add February trace\n",
    "fig.add_trace(\n",
    "    go.Scattermapbox(\n",
    "        lat=feb_data['lat'],\n",
    "        lon=feb_data['lon'],\n",
    "        mode='markers',\n",
    "        marker=dict(\n",
    "            size=feb_data['size'],\n",
    "            sizemode='diameter',\n",
    "            sizeref=2.*max(feb_data['size'])/30,\n",
    "            color=feb_data['min_risk_month'],\n",
    "            colorscale='plasma',  # Adjust colorscale as needed\n",
    "            showscale=False,\n",
    "            cmin=color_min,\n",
    "            cmax=color_max,\n",
    "        ),\n",
    "        text=feb_data['min_risk_month'],\n",
    "        hovertemplate='<b>Lat:</b> %{lat}<br><b>Lon:</b> %{lon}<br><b>Value:</b> %{text}<extra></extra>'\n",
    "    ),\n",
    "    row=1, col=1\n",
    ")\n",
    "\n",
    "# Add August trace\n",
    "fig.add_trace(\n",
    "    go.Scattermapbox(\n",
    "        lat=aug_data['lat'],\n",
    "        lon=aug_data['lon'],\n",
    "        mode='markers',\n",
    "        marker=dict(\n",
    "            size=aug_data['size'],\n",
    "            sizemode='diameter',\n",
    "            sizeref=2.*max(aug_data['size'])/30,\n",
    "            color=aug_data['min_risk_month'],\n",
    "            colorscale='plasma',\n",
    "            showscale=True,\n",
    "            cmin=color_min,\n",
    "            cmax=color_max,\n",
    "            colorbar=dict(x=1.02, len=0.5)\n",
    "        ),\n",
    "        text=aug_data['min_risk_month'],\n",
    "        hovertemplate='<b>Lat:</b> %{lat}<br><b>Lon:</b> %{lon}<br><b>Value:</b> %{text}<extra></extra>'\n",
    "    ),\n",
    "    row=1, col=2\n",
    ")\n",
    "\n",
    "# Update mapbox layouts\n",
    "fig.update_mapboxes(\n",
    "    style=\"carto-positron\",\n",
    "    zoom=4,\n",
    "    center=dict(lat=feb_data['lat'].mean(), lon=feb_data['lon'].mean())\n",
    ")\n",
    "\n",
    "# Update overall layout\n",
    "fig.update_layout(\n",
    "    title_text='Spatial Distribution of Minimal Likelihood in Bottom Depth Bin',\n",
    "    title_x=0.5,\n",
    "    height=600,\n",
    "    width=1600,\n",
    "    showlegend=False\n",
    ")\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cae3414b",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig.write_image(\"fig6_spatial_risk.png\", format=\"png\", scale=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b888e89",
   "metadata": {},
   "source": [
    "## Full Year of Likelihoods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29368c9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "h3_indices = {\n",
    "    'Chignik': {\n",
    "        'Coastal': '840ccebffffffff',\n",
    "    }\n",
    "}\n",
    "\n",
    "sql = '''\n",
    "select \n",
    "    epoch, h3_index, depth_bin, probability\n",
    "from \n",
    "    chinook_depth_full_inference_3_7_2\n",
    "where \n",
    "    run_id = 'fb3f06dc5fd0971a4e7cfdd2e5da5cca391a633f92528e79aa526df347ca0920'\n",
    "    and h3_index = '{h3_index}'\n",
    "'''\n",
    "dfs = []\n",
    "for place, cases in h3_indices.items():\n",
    "    for case, h3_index in cases.items():\n",
    "        data = read_data_w_cache(sql.format(h3_index=h3_index))\n",
    "        data['time'] = pd.to_datetime(data['epoch'], unit='s', utc=False)\n",
    "        # convert to alaska time\n",
    "        data['time'] = data['time'].dt.tz_localize('UTC').dt.tz_convert('America/Anchorage')\n",
    "        data['place'] = place\n",
    "        data['case'] = case\n",
    "        print(data.shape)\n",
    "        dfs.append(data)\n",
    "data = pd.concat(dfs).reset_index(drop=True)\n",
    "print(data.shape)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d0366fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "color_discrete_map = {\n",
    "    25.0: \"#c7e9c0\",  # Light Green\n",
    "    50.0: \"#a1d99b\",  \n",
    "    75.0: \"#74c476\",  \n",
    "    100.0: \"#41ab5d\",  \n",
    "    150.0: \"#238b45\",  \n",
    "    200.0: \"#1b7837\",  \n",
    "    250.0: \"#0868ac\",  \n",
    "    300.0: \"#08519c\",  \n",
    "    400.0: \"#08306b\",  # Deep Blue\n",
    "    500.0: \"#041c40\",  # Darkest Blue (Deepest)\n",
    "}\n",
    "\n",
    "depth_order = sorted(color_discrete_map.keys())\n",
    "data['depth_bin'] = pd.Categorical(data['depth_bin'], categories=depth_order, ordered=True)\n",
    "data['likelihood'] = data['probability']\n",
    "\n",
    "# Now plot with the correct legend order\n",
    "fig = px.line(\n",
    "    data.sort_values('time'), x='time', y='likelihood', color='depth_bin',\n",
    "    color_discrete_map=color_discrete_map,\n",
    "    category_orders={\"depth_bin\": sorted(color_discrete_map.keys())},\n",
    "    title='Likelihood per Depth Bin near Chignik',\n",
    "    height=400, width=1000\n",
    ")\n",
    "\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b007d674",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig.write_image(\"fig8_full_year.png\", format=\"png\", scale=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6002fe5a",
   "metadata": {},
   "source": [
    "## Time of Day Minimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6337248",
   "metadata": {},
   "outputs": [],
   "source": [
    "sql = '''\n",
    "with risk as (\n",
    "    select \n",
    "        month(time) as month, \n",
    "        epoch,\n",
    "        h3_index,\n",
    "        depth_bin,\n",
    "        sin_sun,\n",
    "        cos_sun,\n",
    "        max(elevation) as elevation,\n",
    "        sum(probability) as risk\n",
    "    from \n",
    "        chinook_depth_full_inference_3_7_2\n",
    "    where \n",
    "        run_id = 'fb3f06dc5fd0971a4e7cfdd2e5da5cca391a633f92528e79aa526df347ca0920'\n",
    "        and day(time) = 15\n",
    "    group by \n",
    "        1, 2, 3, 4, 5, 6\n",
    "), max_depth_bin as (\n",
    "    select \n",
    "        month(time) as month, \n",
    "        epoch,\n",
    "        h3_index,\n",
    "        max(depth_bin) as depth_bin\n",
    "    from \n",
    "        chinook_depth_full_inference_3_7_2\n",
    "    where \n",
    "        run_id = 'fb3f06dc5fd0971a4e7cfdd2e5da5cca391a633f92528e79aa526df347ca0920'\n",
    "    group by \n",
    "        1, 2, 3\n",
    "), boundaries as (\n",
    "    select \n",
    "        month,\n",
    "        h3_index,\n",
    "        depth_bin,\n",
    "        elevation,\n",
    "        approx_percentile(risk, 0.05) as min_risk_month,\n",
    "        approx_percentile(risk, 0.95) as max_risk_month\n",
    "    from \n",
    "        risk inner join max_depth_bin using (month, epoch, h3_index, depth_bin)\n",
    "    group by \n",
    "        1, 2, 3, 4\n",
    "), joined as (\n",
    "    select \n",
    "        r.month,\n",
    "        r.h3_index,\n",
    "        r.sin_sun, \n",
    "        r.cos_sun,\n",
    "        r.risk,\n",
    "        b.depth_bin,\n",
    "        b.elevation,\n",
    "        b.min_risk_month,\n",
    "        b.max_risk_month\n",
    "    from \n",
    "        risk r\n",
    "        inner join boundaries b \n",
    "            on r.month = b.month\n",
    "            and r.h3_index = b.h3_index\n",
    ")\n",
    "select \n",
    "    month,\n",
    "    h3_index,\n",
    "    depth_bin,\n",
    "    elevation,\n",
    "    avg(sin_sun) as avg_sin_sun,\n",
    "    avg(cos_sun) as avg_cos_sun\n",
    "from \n",
    "    joined \n",
    "where \n",
    "    risk <= min_risk_month\n",
    "group by \n",
    "    1, 2, 3, 4\n",
    "'''\n",
    "data = read_data_w_cache(sql)\n",
    "data['lat'] = data['h3_index'].apply(lambda x: h3.h3_to_geo(x)[0])\n",
    "data['lon'] = data['h3_index'].apply(lambda x: h3.h3_to_geo(x)[1])\n",
    "print(data.shape)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e6e26d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data[data['depth_bin'] + 100 > -data['elevation']]\n",
    "data['inside_polygon'] = data.apply(lambda row: poly.contains(Point(row['lon'], row['lat'])), axis=1)\n",
    "data = data[data['inside_polygon']]\n",
    "data = data[data['lon'] < -145]\n",
    "data['size'] = 0.01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed2cc1d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "data['sun_is_up'] = np.sign(data['avg_sin_sun'])\n",
    "fig = px.scatter_mapbox(\n",
    "    data[(data['month'] == 2) & (data['depth_bin'] != 25.0)],\n",
    "    lat='lat',\n",
    "    lon='lon',\n",
    "    color='avg_sin_sun',  # Color points by probability\n",
    "    size='size',  # Adjust as needed\n",
    "    size_max=11,  # Adjust as needed\n",
    "    zoom=4,  # Adjust zoom level\n",
    "    mapbox_style=\"carto-positron\",  # Choose a map style,\n",
    "    title='Spatial Pattern of Time of Minimal Risk in February',\n",
    "    range_color=[-1, 1],\n",
    "    height=600,\n",
    "    width=1000,\n",
    "    color_continuous_scale='RdBu_r',  # Red to Blue color scale\n",
    ")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77efffa2",
   "metadata": {},
   "outputs": [],
   "source": [
    "data['sun_is_up'] = np.sign(data['avg_sin_sun'])\n",
    "fig = px.scatter_mapbox(\n",
    "    data[(data['month'] == 8) & (data['depth_bin'] != 25.0)],\n",
    "    lat='lat',\n",
    "    lon='lon',\n",
    "    color='avg_sin_sun',  # Color points by probability\n",
    "    size='size',  # Adjust as needed\n",
    "    size_max=11,  # Adjust as needed\n",
    "    zoom=4,  # Adjust zoom level\n",
    "    mapbox_style=\"carto-positron\",  # Choose a map style,\n",
    "    title='Spatial Pattern of Time of Minimal Risk in August',\n",
    "    range_color=[-1, 1],\n",
    "    height=600,\n",
    "    width=1000,\n",
    "    color_continuous_scale='RdBu_r',  # Red to Blue col.3or scale\n",
    ")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df0ebf82",
   "metadata": {},
   "outputs": [],
   "source": [
    "from plotly.subplots import make_subplots\n",
    "import plotly.graph_objects as go\n",
    "\n",
    "# Create subplot figure with 1 row and 2 columns\n",
    "fig = make_subplots(\n",
    "    rows=1, cols=2,\n",
    "    subplot_titles=('February', 'August'),\n",
    "    specs=[[{'type': 'mapbox'}, {'type': 'mapbox'}]],\n",
    "    horizontal_spacing=0.01\n",
    ")\n",
    "\n",
    "# Prepare February data\n",
    "feb_data = data[(data['month'] == 2) & (data['depth_bin'] != 25.0)]\n",
    "\n",
    "# Prepare August data\n",
    "aug_data = data[(data['month'] == 8) & (data['depth_bin'] != 25.0)]\n",
    "\n",
    "# Use fixed color range\n",
    "color_min = -1\n",
    "color_max = 1\n",
    "\n",
    "# Add February trace\n",
    "fig.add_trace(\n",
    "    go.Scattermapbox(\n",
    "        lat=feb_data['lat'],\n",
    "        lon=feb_data['lon'],\n",
    "        mode='markers',\n",
    "        marker=dict(\n",
    "            size=feb_data['size'],\n",
    "            sizemode='diameter',\n",
    "            sizeref=2.*max(feb_data['size'])/30,\n",
    "            color=feb_data['avg_sin_sun'],\n",
    "            colorscale='RdBu_r',\n",
    "            showscale=False,\n",
    "            cmin=color_min,\n",
    "            cmax=color_max,\n",
    "        ),\n",
    "        text=feb_data['avg_sin_sun'],\n",
    "        hovertemplate='<b>Lat:</b> %{lat}<br><b>Lon:</b> %{lon}<br><b>Value:</b> %{text}<extra></extra>'\n",
    "    ),\n",
    "    row=1, col=1\n",
    ")\n",
    "\n",
    "# Add August trace\n",
    "fig.add_trace(\n",
    "    go.Scattermapbox(\n",
    "        lat=aug_data['lat'],\n",
    "        lon=aug_data['lon'],\n",
    "        mode='markers',\n",
    "        marker=dict(\n",
    "            size=aug_data['size'],\n",
    "            sizemode='diameter',\n",
    "            sizeref=2.*max(aug_data['size'])/30,\n",
    "            color=aug_data['avg_sin_sun'],\n",
    "            colorscale='RdBu_r',\n",
    "            showscale=True,\n",
    "            cmin=color_min,\n",
    "            cmax=color_max,\n",
    "            colorbar=dict(x=1.02, len=0.5)\n",
    "        ),\n",
    "        text=aug_data['avg_sin_sun'],\n",
    "        hovertemplate='<b>Lat:</b> %{lat}<br><b>Lon:</b> %{lon}<br><b>Value:</b> %{text}<extra></extra>'\n",
    "    ),\n",
    "    row=1, col=2\n",
    ")\n",
    "\n",
    "# Update mapbox layouts\n",
    "fig.update_mapboxes(\n",
    "    style=\"carto-positron\",\n",
    "    zoom=4,\n",
    "    center=dict(lat=feb_data['lat'].mean(), lon=feb_data['lon'].mean())\n",
    ")\n",
    "\n",
    "# Update overall layout\n",
    "fig.update_layout(\n",
    "    title_text='Spatial Pattern of Time of Minimal Likelihood',\n",
    "    title_x=0.5,\n",
    "    height=600,\n",
    "    width=1600,\n",
    "    showlegend=False\n",
    ")\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "670934d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig.write_image(\"fig7_time_risk.png\", format=\"png\", scale=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fa60be4",
   "metadata": {},
   "source": [
    "## Paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce648a6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "sql = '''\n",
    "select\n",
    "    tag_key, epoch, longitude, latitude\n",
    "from \n",
    "    mgietzmann_tag_tracks\n",
    "where\n",
    "    upload_key = 'mgietzmann'\n",
    "'''\n",
    "data = read_data_w_cache(sql)\n",
    "data[\"month\"] = pd.to_datetime(data[\"epoch\"], unit=\"s\").dt.month\n",
    "print(data.shape)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "458edf4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = px.scatter_map(\n",
    "    data, lat='latitude', lon='longitude',\n",
    "    zoom=3, center=dict(lat=data['latitude'].mean(), lon=data['longitude'].mean()),\n",
    "    height=700, width=1000, title=\"Chinook Salmon Tag Tracks\", color=\"month\"\n",
    ")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81b53556",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig.write_image(\"fig1_tracks.png\", format=\"png\", scale=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2277be87",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
